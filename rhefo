#!/bin/bash

#	Copyright (C) 2023-present SMAGGHE Clément (https://github.com/T-3B).
#
#	This program is free software: you can redistribute it and/or modify it under the terms of the Server Side Public License, version 1.
#
#	You should have received a copy of the Server Side Public License along with this program. If not, see <http://www.mongodb.com/licensing/server-side-public-license>.


# already tested dash, but exec time is mainly optimizers (shell commands interpretation time is neglible) and overcomplicates things (like I should write compressFile in another script file because cannot export function in dash - and env_parallel cannot use it)

#### Note on DeflOpt.exe and defluff (it was decided to not use them at all in this script):
#	Tested on a dozen .gz and .zip files (< 1MiB).
#	- defluff: can gain a few bytes (max 3) instantly after `ect -9 --mt-deflate` on rare cases (can be beaten with `ect -99999`), some times (more common) it adds a byte to the deflate-compressed stream, and most of the time no diff
#	- DeflOpt.exe: silently drops empty files from zip, never bigger output. In rare cases a few bytes (max 3) are saved (instantly again), but increasing ect's iterations beats it. Big issue: windows program.
#	for APNG, defluff can save about 0.07% of filesize instantly. I prefer to avoid these tools.

# for `dd`, if writing to existing output file, `dd status=none bs=4 count=1 seek=6 conv=notrunc oflag=seek_bytes iflag=fullblock of="$tmp"`

# features to add, fixes needed, etc are written with a 'TODO' in capital letters; 'todo' is written for stuff to change with very very low priority (mainly a nice thing to have, but almost useless because too rare), everything completely works without issues even with 'todo'

# TODO add globarchnoroot to remove root folder if there is only one folder
# TODO add option to remove __MACOSX folder from inside archives add to globarch-lossy

# TODO for all the solid archive compressors, different file sortings will give different sizes (remember, do it too in TAR for .tar-based)
#		TODOOOOOOOOOOOOOO binsort (binsort use simhash + find the shortest path - something like the Voyageur de Commerce - so try implementing with tlsh and nilsimsa)
#		binsort wins by a large margin a greedy algorithm (take the closest file - with minimal distance - each time) with nilsimsa - didn't try tlsh as the CLI sucks

# TODO control memory: take only what's needed (backup, copy, ...) in TMPDIR, if taking more (tmp2, decompressing archive, ...) do that in each case (specific to a mimie-type)
# put in a file what we can still use in mem to be safe, if not enough space wait until we can (can we do that with semaphores with parallel ?)
# => add a setting "globmaxmem" to limit the maximum memory used at the same time in the TMPDIR folder (parallel has some parameter to suspend jobs if not enough mem - search for "mem" in man page)

# TODO add --glob-nosort to not sort input by size (if input is given with something like find)

set -a  # export var+fct automatically
set -m  # All processes run in a separate process group (needed for Ctrl+C "trick")
version=v0.0.1
help=$(echo 'Really High Efficient File Optimizer (RHEFO), version '$version'. Under SSPL.
For updates, supported files, dependencies, issues, license and many more, see:
  https://github.com/T-3B/rhefo
Use this script with caution!
This script supports directories and files, but others (like symlinks) were NOT
tested (and I do NOT know if the script will work or "break" your machine)!

Usage: `rhefo [options] [--] INPUT [INPUT ...]`
INPUT can be folder or file, and several INPUTs can be given.

List of options (global ones first, then grouped by file type):
--help | -h
  print help; use `-h` for options summary, `--help` for full help message
--glob-filemask=<mask> | -m <mask>
  only filenames matching the <mask> will be optimized (e.g. "*.mp3")
--glob-insane | -9	better compression
  if set, all "insane" flags are set too (no quality/compatibility loss)
  to "compress" better, consider --glob-lossy (only for lossy metadata)
  compatibility-break and lossy flags are NOT set; TAKES A LOT OF TIME!!!
--glob-jobs=<N> | -j<N>
  <N> files are optimized in parallel; default: same as --glob-threads
--glob-keeptime | -k
  if set, input access and modification times are kept
--glob-lossy | -l	better compression, lossy
  if set, all lossy flags are set (except the more agressive --glob-strip)
  lossy flags *only* act on metadata; most of time they remove what
    is not really needed (such as the version of FLAC encoder)
--glob-norecur		worse compression, faster
  if set, do not compress embedded files (no "recursion")
--glob-output=<path> | -o <path>
  <path> is output folder; default: inplace (overwrite input files)
  even if set, --glob-tmp is still used
--glob-prefix=<prefix> | -p <prefix>
  Prefix to add to all processed files (--glob-output can still be used)
--glob-strip | -s	better compression, lossy
  if set, strip/remove ALL metadata/exif; see the less aggressive --glob-lossy
--glob-threads=<N> | -t<N>
  <N> logic cpu processors used by this script; default: all (see --glob-jobs)
--glob-tmp=<path> <path>
  <path> is a directory intensively used for r/w; default is `/dev/shm`
  if does not exist, or cannot r/w in it, defaults to `/tmp`
--glob-update | -y
  if set, will overwrite files in --glob-output
--flac-insane		better compression (~0.1% save), far slower (~200x)
  if set, run FLAC with the apodization function `subdivide_tukey(40)`
--flac-lossy		better compression, lossy
  if set, vendor string from VORBIS_COMMENT is removed
    all blocks except VORBIS_COMMENT & PICTURE are removed (seektable,...)
    if there are no tags, then VORBIS_COMMENT block is removed too
  all PICTUREs are compressed with --glob-strip (drop all APICs metadata)
    PICTUREs type and description are kept, but not e.g. EXIF
--flac-subset		worse compression, faster
  if set, use subset mode (HW decode guaranteed); default: non-subset
--gzip-insane		better compression, far slower (TODO benchmark)
  if set, use 99999 iterations; default: 9
--gzip-lossy		better compression, lossy
  if set, do not store the original decompressed filename
  default is to store it only if archive is not `originalName.gz`
--mp3-lossy		better compression (208 bytes less), lossy
  if set, do not write a Xing frame; some softwares will show a wrong duration
--png-insane		better compression, far slower (TODO benchmark)
  if set, use 99999 iterations; default: 9 (PNG), 99 (APNG)
--zip-insane		better compression, far slower (TODO benchmark)
  if set, use 99999 iterations; default: 9
--zip-nodeflate		better compression, slower, compatibility
  if set, do not use only Deflate but also Deflate64,LZMA,PPMd,BZip2,Zstd,XZ
  default is to only use Deflate if input has only Deflate streams
  warning, many softwares do NOT support other stream but Deflate

Use `grep` with this help, it is easy! Try `grep -e --flac -e --glob`.
Want further help/understanding on what/why really is done under the hood? Read
the comments in this script. You could learn how to compress even more than this
script will allow you (but you probably will compress 1 KB per minute).
Do not let me think I wrote these comments for nothing :´)

If you think the script is taking too much time, do not hesitate to hit Ctrl+C!
The first Ctrl+C will tell RHEFO to not start any new job and to gently finish
currently running jobs (all temp files are cleaned). The second will abruptly
stop all jobs, and information on files already processed will be displayed in
less than a second (temp files are NOT cleaned, and there may be many of them).

Examples of usage:
# optimize recursively current dir, inplace
rhefo .
# optimize as much as possible (TAKES TIME!!!) recursively current dir, inplace,
# keep timestamps and remove some useless metadata
rhefo -9kl .
# optimize with only 2 threads, and copy /indir *inside* /outdir
rhefo -o /outdir -j2 /indir
# optimize 2 files with default settings and write output to an existing /outdir
rhefo -o /outdir <firstFile> <secondFile>
# optimize all FLAC files in /indir, recursively and in hidden dirs and
# output will be copied to /outdir (folders/files tree is recreated from /indir)
rhefo -o /outdir -m "*.flac" /path/to/dir
# same as above, but flattened (no subdirectories in /outdir)
find -name "*.flac" -type f -print0 | xargs -0 rhefo -o /outdir' |\
	GREP_COLORS=mt=\;33 grep --color=always -E '^--[[:alnum:]_-]+|$' | GREP_COLORS=mt=\;36 grep --color=always -P '(?<= \| )-\w|$' | GREP_COLORS=mt=\;32 grep --color=always 'better compression\|$' | GREP_COLORS=mt=\;31 grep --color=always 'worse compression\|$' | GREP_COLORS=mt=1 grep --color=always -P '(?<=, )(lossy|compatibility)|$' | GREP_COLORS=mt=\;35 grep --color=always '^#.*\|$'
)

# Will parse arguments, and then start the whole optimization process (if no errors in the arguments)
parseArgs() {  # not using `local` vars because this fct is only exectued once
	[ $(printf '\1' | od -dAn) = 1 ] || error 'This script was not tested on BIG ENDIAN devices. I mainly use `printf %x` with\nnumbers of up to 4 bytes.\nPLEASE, open an issue and if you have time HELP ME supporting this architecture\nby simply testing! This would really help a lot, since I only have little-endian\ndevices. Seriously, please.\n'
	getopt -T && { error 'Your `getopt` is not compatible with this script. Open an issue.' 4;}
	args=$(getopt -o hm:9j:klno:p:st:y -l help,glob-filemask:,glob-insane,glob-jobs:,glob-keeptime,glob-lossy,glob-norecur,glob-output:,glob-prefix:,glob-strip,glob-threads:,glob-tmp:,glob-update,flac-insane,flac-lossy,flac-subset,gzip-insane,gzip-lossy,mp3-lossy,png-insane,zip-insane -n rhefo -s bash -- "$@")
	(($?)) && error 'Could not parse args. See the help message `rhefo -h`.'
	TMPDIR=/dev/shm  # mktemp uses directly TMPDIR, so set it instead of another variable globtmp (or we should specify this variable as an argument)
	eval set -- "$args"
	while :
	do case "$1" in
			-h)						echo "${help%%$'\n'*}"; echo "$help" | grep '\[;33m'; echo 'Run `rhefo --help` for the full help.'; exit;;
			--help)					echo "$help"; exit;;
			-m | --glob-filemask)	[ "$2" ] || error "Filemask is empty."; globfilemask=$2; shift;;
			-9 | --glob-insane)		flacinsane=;gzipinsane=;pnginsane=;zipinsane=;;
			-j | --glob-jobs)		((0<$2)) || error "Wrong jobs int: '$2'."; globjobs=$2; shift;;
			-k | --glob-keeptime)	globkeeptime=;;
			-l | --glob-lossy)		gziplossy=;flaclossy=;mp3lossy=;;
			-o | --glob-output) 	[[ -d "$2" || -w "$2" ]] || error "Output directory '$2' does not exist or cannot write to it."; globoutput=$(realpath "$2" 2>/dev/null); shift;;
			--glob-norecur)			globnorecur=;;
			-p | --glob-prefix)		[ "$2" ] || error 'Prefix is empty.'; globprefix=$2; shift;;
			-s | --glob-strip)		globstrip=;gziplossy=;flaclossy=;mp3lossy=;;
			-t | --glob-threads)	((0<$2 && $2<=$(nproc --all))) || error "Wrong threads int: '$2'."; threadlimit $2; shift;;
			--glob-tmp)				[[ -d "$2" && -r "$2" && -w "$2" ]] && TMPDIR=$(realpath "$2") || { warning 'Could not use given --glob-tmp, using "/tmp" instead.'; TMPDIR=/tmp;}; shift;;
			-y | --glob-update)		globupdate=;;
			--flac-insane)			flacinsane=;;
			--flac-lossy)			flaclossy;;
			--flac-subset)			flacsubset=;;
			--gzip-insane)			gzipinsane=;;
			--gzip-lossy)			gziplossy=;;
			--mp3-lossy)			mp3lossy=;;
			--png-insane)			pnginsane=;;
			--zip-insane)			zipinsane=;;
			--zip-nodeflate)		zipnodeflate=;;
			--) 					shift; break;;
			*) 						error "Unexpected argument '$1'. See the help message \`rhefo -h\`."
		esac
		shift
	done
	(($#)) || error 'No input given. See the help message `rhefo -h`.'
	for i do [ -r "$i" ] || error "Input '$i' does not exist or cannot read it."; done

	printf '0\n0\n0\n' >"${globstatsfile=$(mktemp --tmpdir rhefo_${version}_tmpXXX)}"  # file where stats are wrote - to allow edit in subshells since we use `parallel`; 1st line is saved bytes, 2nd is input files size, 3rd is nbr input files

	# extract embedded add-ins
	addinsDir=$(mktemp -dp/tmp rhefo_${version}_tmpXXX)  # use /tmp for temp dir because we don't want weird chars (like ':') since we add it to PATH
	
	exitPATH=$addinsDir:$PATH
	dd status=none bs=4k iflag=fullblock iflag=skip_bytes skip=$((6+$(grep -bm1 '^#EOF#$' "$(realpath -- "$BASH_SOURCE")" | cut -f1 -d:))) <"$(realpath -- "$BASH_SOURCE")" | base64 -d | tar xC "$addinsDir"
	chmod -R +x "$addinsDir"

	# create all the dir-tree to output folder
	[ -v globoutput ] && { for i do [ -d "$i" ] && ([ "${globoutput#$(realpath "$i")}" = "$globoutput" ] || error "The --glob-output folder can't be inside an input folder."; cd -- "$i"; find -type d -exec mkdir -p "$globoutput/$(basename "$(realpath "$i")")/{}" \;); done;}
	# get absolute path, find all files (print size, filepath, input folderpath), sort (biggest size first), compress in parallel
	{
		# TODO parallel --memsuspend
		realpath -z -- "$@" | xargs -0i find '{}' -type f ${globfilemask+-name "$globfilemask"} -printf '%s\0%P\0%H\0' | perl -0ne 'push @rec, $_; if ($#rec == 2) { push @items, join("", @rec); @rec = (); } END { print(join("", sort { $b <=> $a } @items)) }' | parallel -j${globjobs-100%} -0L3 --lb --bar compressFile {2} {3} {1} 1
		# Thanks for the people helping me finding a way to sort by filesize (sorting by group of 3 elements): https://stackoverflow.com/a/76028193/13227011
		# TODO don't compressFile duplicates (explicitly twice same input or implicitely - with the file and the parent folder)
		# TODO test with filenames having $@-*

		((s=SECONDS, h=s/3600, m=s/60-h*60, s%=60))
		set -- $(<"$globstatsfile")
		printf "\rCongrats! Processed %d files in %s and saved %sB (%.3f%%)!\n\a" $3 $(((h)) && printf ${h}h; ((m)) && printf ${m}m)${s}s $(numfmt --to=iec-i --format="%.2f" $1) $((1000000*$1/($2?$2:1)))e-4
		rm -r "$globstatsfile" "$addinsDir"
	} &  # all the code is done in background so it won't be killed by Ctrl+C
	while ! wait; do :; done  # each Ctrl+C will kill `wait` (1st hit: no new job, 2nd: kill parallel)
}


# restrict this script to use the $1 *least used* CPU processors (or threads)
threadlimit() {
    # sum idle ($4) and io-wait ($5) ticks, substract between 2 reads (1 sec between), take $1 biggest numbers (will be our cpu threads to use with taskset)
	# could have used `taskset -acp 0-$(($1-1)) $$`, but doesn't "work" if > 1 instance of RHEFO is running
	[ $(nproc) = $(nproc --all) ] || { warning 'This script does NOT have access to all cpu threads, ignoring --glob-threads.'; return;}

	taskset -acp $(paste <(awk '/^cpu[0-9]/{print $4+$5}' /proc/stat) <(sleep 1; awk '/^cpu[0-9]/{print $4+$5}' /proc/stat) \
					| awk '{print $2-$1, NR-1}' | sort -n | tail -$1 | cut -d' ' -f2 | paste -sd,) $$ >/dev/null
}


# TODO better to change these2= 2 fct to only support reading data from stdin ?
# convert binary data to hexadecimal;	$1=filepath (or empty for stdin)	$2=index/offset of byte to print (in decimal)	$3=nbr of bytes to print (if no set then 1)
getBytes() {
	od --endian=big -An -j$2 -N${3-1} -vtx1 ${1:+"$1"} | tr -d ' \n'  # remove spaces and newline from output; for now everything I used only needed big endian
}

# convert int to binary data ("1" => 0x1) BIG endian;	$1=integer	$2=nbr of output bytes (padding with 0's if needed - "1" => 0x0000001)
intToBytes() {
	local i
	for i in $(seq $((8*$2-8)) -8 0)
	do printf $(printf '\\x%x' $(($1>>i&255)))
	done
}

# over all the input filepaths (having THE SAME NAME BEFORE LAST DOT '.'), find the smallest file, then rename it (with overwriting) without its last extension '.*', then delete all inputs
catchSmallestFile() {
	local a=$(find "$@" -printf '%s %f\0' | sort -nz | head -zn1 | tr -d \\0)  # need tr, otherwise we would have a warning msg for the trailing NULL byte
	a=${a#* }
	mv "$a" "${a%.*}"
	rm -f "$@"  # -f to not print err msg, since there's a missing file ("$a") 
}

# Using ffmpeg, extract each stream to a separate file, compress the streams, and finally remux all of them with the correct metadata. $1 is the fullpath; $2 is blacklist of streams to not optimize (mp3, mjpeg, ...)
# TODO $2
ffCompressStreams() {
	local i=0 c f name=${1##*/} IFS=/ tmp=${1%/*}/a${1##*/}
	c=$(AV_LOG_FORCE_COLOR=1 ffmpeg -v warning -i "$1" -map 0 -f null - 2>&1 >/dev/null)  # check for malformed streams/file
	if (($?)) || [ "$c" ]
	then echo -e "\r\e[1;41m$1: got warning or error while parsing. Could not extract streams.\e[0m\n$c"
		return 1
	fi
	cd "${1%/*}"  # trick in order to use IFS=/ as a separator since that char is not allowed in filenames
	while read -r c;
	do f+="-map/0:$i/-c/copy/$name.$((i++)).$c/"  # TODO see if we can inline that with the ffmpeg command; at least I'm sure with can inline with ffprobe
	done < <(ffprobe -v warning -show_entries stream=codec_name -of default=nk=1:nw=1 "$1")  # `-of csv=p=0` doesn't work if stream has SIDE_DATA (it would have a trailing ',')
	ffmpeg -v warning -i "$1" $f
	f=
	while ((i--))
	do	compressFile "$name.$i".*  # will expand automatically to the correct file ext
		c+="-i/"
		c+="$name.$i".*  # TODO see if inline is possible, and check if works when mixing (c[0] then f[0] then c[1] ...)
		c+=/
		f+="-map_metadata:s:$i/0:s:$i/-map/$((i+1))/"
	done
	mv "$1" "$tmp"
	# TODO ffmpeg will override `encoder` metadata (global metadata)
	ffmpeg -v warning -i "$tmp" $c $f -c copy -fflags +bitexact "$1"
	rm "$tmp" "$1".*
	# ffmpeg -i fuckedup.mp3 -i p.mp3 -i second.jpg -i first.jpg -map_metadata:s:0 0:s:0 -map 1 -map_metadata:s:1 0:s:1 -map 2 -map_metadata:s:2 0:s:2 -map 3 -fflags +bitexact -codec copy fffout.mp3
	cd - >/dev/null
	# [ ${globnotest-x} ] && [ "$()" != "$()" ] && { echo "$tmp: recompression was NOT lossless. You should open an issue. Input file was kept.">&2; mv "9$tmp" "$tmp";}  #TODO
}

# TODO can't we drop $4 and use $3 instead ?
# $1=filepath	$2=prefixpath	$3=filesize		$4=inIsNotTMP		("$2/$1" = full absolute input path)	(do NOT set $4 when this is a subcall from another compressFile - e.g. when compressFile a file from an extracted ZIP file); none can have spaces etc
compressFile() {	# warning: $1 can be empty
	[[ ! $4 && -v globnorecur ]] && return  # if this is a subcall compressFile and globnorecur is set, then do not optimize this file (as it's an embedded one)
	set -a  # export everything automaticall (e.g. sub-parallel calls)
	local a p v  # variables for temporary/intermediate values, ONLY SET THEM IN THE CASE SWITCH
	local atime mtime size mime in=$2${1:+/$1} tmp tmpname tmp2 out
	atime=$(stat -c%x "$in")
	mtime=$(stat -c%y "$in")
	tmp=$(mktemp --tmpdir --suff=."${in##*/}" XXX)  # always use $tmp, even if recompressing the files that were inside an archive, to be safe with wildcards "$tmp".* (when bruteforcing compression args) - also added a dot (safe to drop the extension for some compression formats like GZ)
	#TODO check if $TMPDIR has enough free mem
	out=$in
	[[ $4 && -v globoutput ]] && out=$globoutput/${2##*/}${1:+/$1}
	[[ $4 && -v globprefix ]] && out=${out%/*}/$globprefix${out##*/}
	[[ $4 && (-v globoutput || -v globprefix) && ! -v globupdate && -e "$out" ]] && { warning "'$out' already exists, file not compressed nor updated. Rerun with -y to overwrite files in output directory, or with -p to add a prefix.";rm -f "$tmp";return;}
	cp "$in" "$tmp"  # TODO remove this and insert it in each switch case (since we need to read it once, read it when needed - and run directly a command with the processed data)
	size=${3-$(wc -c <"$tmp")}
	tmpname=${tmp##*/}
	tmp2=${tmp%/*}/0$tmpname  # needs sometimes TODO check if can delete it (not use tmp2 anymore), since we have the certitude that in!=tmp

	# TODO if mime=application/octet-stream, use FFmpeg to try to get the container name (or use a file mapping filextensions to mime-type)
	case $(file -b --mime-type "$tmp") in  # see here for known MIME types: /usr/share/mime/types
		application/gzip | application/x-gzip)
			# tested tools: zopfli, zopfli MrKrzYch00's mod, gzip, 7z, minigzip (from minizip-ng). Tested on all files from silesia.tar (ect is far faster than zopfli(mod), and always gives smaller files - even when file is 1KB; ECT << zopfli < zopfli_mrkrzych00 << gzip); zopfli_mrkrzych00 --i9999 --mui999 --slowfix --t0 --pass9 --all androidsdk.svg
			p=$(gzip -Nl "$tmp")
			p=${p##* }  # p= original decomp filename
			tmp2=${tmp2%.*}  # TODO remove any extension, or only if extension is GZ (case *in*sensitive) ?
			gzip -dc "$tmp" >"$tmp2"
			compressFile "$tmp2"
			cd "$(mktemp -d)"
			mv "$tmp" "$p"  # TODO not safe at all, and use tmp2 (not tmp)
			gzip -1c$([[ -v gziplossy || "$p.gz" = "$tmpname" ]] && echo n) "$p" >"$tmp"
			cd - >/dev/null
			rm -r "$OLDPWD"
			ect -9${gzipinsane+9999} --mt-deflate -gzip --strict "$tmp";;  # using strict won't recompress embedded file
		application/pdf)  # there is also `mutool extract`.
			# TODO: best combination: cpdf -> pdfsizeopt -> mutool clean -> qpdf
			# Warning I don't think it's always the same order giving smallest file
			mutool clean -gggg "$tmp" "$tmp"  # at least clean once
			p=$(wc -c <"$tmp")
			while v=$p; mutool clean -gggg "$tmp" "$tmp"; p=$(wc -c <"$tmp"); ((p<v)); do :; done  # repeat as many time to "garbage collect objects/streams + merge/reuse duplicates + compact cross ref table", I saw a file that needed 7 iterations
			qpdf --recompress-flate --compression-level=9 --object-streams=generate --decode-level=specialized --replace-input "$tmp"  # don't use decode-level=all or bigger output
			# TODO for lossless check, see `mutool draw` (can convert pdf to vector graphics :chad:)
			# TODO check with pdfsizeopt (see minuimus for that, nice args), or see parser here : https://blog.didierstevens.com/programs/pdf-tools/ to extract objects
			# pdfsizeopt needed python2, ghostscript, sam2p, png22pnm
			# pdfsizeopt --optimize --use-pngout=yes --use-jbig2=yes --use-sam2p-pr=yes --use-image-optimizer='ect -999 -strip --mt-deflate %(targetfnq)s' in.pdf out.pdf
			# mutool draw -w 2048 -s 5 in.pdf  # "close" to lossless checksum (`-F png` by default) will check md5 of PNG
			# mutool draw -o page%d.svg in.pdf && sha256sum page*.svg  # will check sha256 of SVG (vectors!!!) super powerfull and works, just need temp files 
			;;
		application/octet-stream)  # can be many many things
			#ffCompressStreams "$tmp";;  # TODO test for MP3
			;;
		application/x-tar | application/x-cbt)
			v=$(mktemp -d)
			tar xf "$tmp" -C"$v"
			rm "$tmp"
			compressTmpFolder "$v"
			find "$v" \( ! -type d -o -empty \) -printf %P\\0 | tar cf "$tmp" -b1 --no-recursion --null -C"$v" -T-  # use `find` to not store any prefix (`./`) in tar contents; by default `tar` uses 20x512 bytes block for alignment, use `-b1` for only one; do not store non-empty dir as a separate element in the tar
			rm -r "$v";;
		application/zip | application/zip-compressed | application/x-zip-compressed)
			# TODOOOOOOOOOOOO WARNING some uncompressed files need to stay uncompressed (like mimetype in epub - epub is a "disguised" ZIP). Use extension to differentiate EPUB from ZIP
			# TODO check application/epub+zip, application/vnd.comicbook+zip, application/x-zip-compressed-fb2,
			# TODO for 7z there are plug-ins : https://github.com/mcmilk/7-Zip-zstd (zstd, Brotli, LZ4, LZ5, Lizard, Fast LZMA2)
			# TODO  EPUBs, which require that the first entry in the ZIP be the mimetype file
			#  TODO for android APK: "aur/apk-resigner 1-2 (+8 0.00)		A bash script utility that resigns the Android Package (APK) files (Android applications) with different certificates."
			# search "apk" or "android" with yay, because many utils exist to edit apk
			# tested softwares: minizip-ng, 7z, kzip, ect
			
			# TODOOOOOOO input archived files do not keep their orig date
			v=$(mktemp -d)
			p=$(zipdetails "$tmp" | grep Compression\ Method | grep -vce "0008 'Deflated'" -e "0000 'Stored'")  # count all embedded files stored in another method than Deflate or Store
			7zz x "$tmp" -o"$v" >/dev/null
			rm "$tmp"
			compressTmpFolder "$v"
			if [ -v zipnodeflate ] || ((p))
			then : # TODO
			# TODOOOOOOOOOOOOOOOOOOOO remove zopfli_mrkrzych00 since it's slooooow; or create a ZIP per file (using zopfli_mrkrzych00 since it's the only one I know forcing compression mode even if output is bigger), then ECT'd them in parallel and finally merge them
			# TODO do not call zopfli if all files are compressed (no file is in store mode - zipdetails)
			else (cd "$v"/..; zopfli_mrkrzych00 --i1 --v0 --zip --dir "${v##*/}"  # `zip`, `7z` will both use 'Stored' if Deflate is larger, but not zopfli_mrkrzych00 - really usefull since ECT is the best Deflate compressor but only recompress Deflate streams (not 'Stored') and needs a zip as input
					cd "${v##*/}"; find -empty -printf %P\\0 | xargs -r0 7zz a ../"${v##*/}".zip)  # zopfli won't store dirs as separate stream in zip. WARNING zopfli drop empty dirs and files!
				rm -r "$v"
				mv "$v".zip "$tmp"
				ect -9${zipinsane+9999} -quiet -zip --strict --mt-deflate "$tmp"  # using --strict makes sure ECT does not try to optimize archived files (so it will only optimize Deflate compression in ZIP, not files themselves)
			fi
			# TODO for apk, do not extract to optimize inside (would require apk-resigner - AUR; + zipalign; + some uncompressed files should stay uncompressed https://stackoverflow.com/q/25425172/13227011)

			# TODO for ZIP and 7z, we should bruteforce different compression method
			# ZIP: no (solid) block compression, so easier: each file is distinct from the others, so just bruteforce method compression and select the smallest embedded file. Deflate Deflate64 BZip2 LZMA XZ Zstd PPMd and perhaps more
				# minizip-ng: Deflate (no flag), Bzip2, LZMA, Zstd		7zip: Deflate, Deflate64 , BZip2

			# Note: with 7zip many params do not have max values (such as -mpass). Try if more than the maximum written in the manual can bring ameliorations. For Deflate ECT is still better.
			# be really carefull since p7zip (linux) is outdated 17.0.0 while 7-zip is 22.0.1. There is a static x64 build
			;;
		audio/flac | audio/x-flac)  # Tested softwares (with different genres, 44.1 and 96 kHz, 16 and 24-bit, stereo): fork of reference FLAC 1.4.2 encoder https://github.com/ktmf01/flac; FLACOut.exe; CUETools.Flake.exe 2.2.2 --vbr 3 -11 -P 0 --lax --no-seektable -r 8 -e 32 -l 32 (tested different --window-method, -w, --vbr <0..4>, and did beat reference FLAC encoder *only* if I did *not* try -A functions); justinruggles' Flake
			# Note on FLAC compression: I made several benchmarks (10 encodes with different settings for 40 wav - PCM s16 44.1 kHz - files).
			# Don't "bruteforce" apodizations functions. From the results, it is far better to use only `subdivide_tukey', and the more the number given to it, the better the compression.
			# If trying multiple apodization functions, there are 2 cons: it takes longer because FLAC will estimates them all, and it can *increase* the output filesize because apodization fcts are *estimated* (and order matters).
			# For easy copy-paste, here is a command using 32 apodization fcts (the max allowed). Did not check if order was "optimal". Nearly the same size as only using `subdivide_tukey(40)' (by ~0.01%), but taking 1.7x longer. Therefore if better compression ratio is needed I recommend only increasing the value given to `subdivide_tukey'.
			#flac in.flac -o out.flac -A subdivide_tukey\(5\) -A subdivide_tukey\(10\) -A subdivide_tukey\(15\) -A subdivide_tukey\(20\) -A subdivide_tukey\(25\) -A subdivide_tukey\(30\) -A gauss\(0.1\) -A tukey\(10\) -A tukey\(15\) -A tukey\(20\) -A tukey\(25\) -A partial_tukey\(10\) -A partial_tukey\(15\) -A partial_tukey\(20\) -A partial_tukey\(25\) -A punchout_tukey\(10\) -A punchout_tukey\(15\) -A punchout_tukey\(20\) -A punchout_tukey\(25\) -A welch -A bartlett -A bartlett_hann -A blackman -A blackman_harris_4term_92db -A connes -A flattop -A hamming -A hann -A kaiser_bessel -A nuttall -A rectangle -A triangle -8epP 0 --no-seektable -r 15 -l 32 --lax
			#subdivide_tukey(5);gauss(0.1);tukey(5);partial_tukey(5);punchout_tukey(5);welch;bartlett;bartlett_hann;blackman;blackman_harris_4term_92db;connes;flattop;hamming;hann;kaiser_bessel;nuttall;rectangle;triangle

			# TODO detect and compress if mono was encoded as stereo
			# TODO flac can be in ogg/oga!
			# TODO Ogg only supports Opus, Vorbis, FLAC, A-law PCM, μ-law PCM, IEEE floating-point PCM, Speex and CELT.[e] OGMtools supports MP3 and AC-3 in Ogg.
			# TODO bruteforce blocksize (the size providing best ratio - mean - is 4096 with actual flags)
			
			# Warning! Do not use ffmpeg as it merges all tags with the same key within a single tag (with ';' as a separator).
			
			if ! [ -v globstrip ]
			then a=$(metaflac --list --block-type=PICTURE "$tmp" | grep -oP '(?<=^METADATA block #)\d+$')  # PICTURE blocks IDs
				# extract pictures (pics themselves and blocks), filenames written to array 'a'
				parallel 'metaflac --block-number={} --export-picture-to="$tmp".{} "$tmp"; metaflac --block-number={} --list --data-format=binary "$tmp" >"$tmp".{}.block' ::: $a
				metaflac --remove --block-type=PICTURE "$tmp"  # remove pics, since we append them later
				globstrip= parallel --lb 's=$(wc -c <"$tmp".{}); compressFile "$tmp".{}; t=$(wc -c <"$tmp".{}); { intToBytes $((0x$(getBytes "" 0 4)-s+t)) 4; head -c $(($(wc -c <"$tmp".{}.block)-s-8)); intToBytes $t 4; cat "$tmp".{};} <"$tmp".{}.block >"$tmp".{}.blockNew; rm "$tmp".{}{,.block}' ::: $a & # compress PICTURES in parallel with --glob-strip; Taking the first 4 bytes as block length even if the first one isn't, easier to implement and works. We update block length, image data length and image data.
				# now the {}.blockNew contains the opt picture, with correct size. todo Colors (the 4 bytes just before pic size) could be changed for example by ECT. Colors are the number of indexed colors; tried and everything works on PC if it's not updated; we could use `identify -verbose "$tmp"` and look at "Colormap entries:", if not in output then not indexed (at least for PNG), would add a dependency I don't want. Could also remove all block from FLAC, try to import pic and let FLAC figure it out (Colors) for me then copy (too much work for what it brings)
			fi
			flac "$tmp" -smepfb 4096 -P 0 -r ${flacsubset+8 -l $(($(metaflac --show-sample-rate "$tmp")>48000?32:12))} ${flacsubset-15 -l 32 --lax} -A subdivide_tukey\(4${flacinsane+0}\)
			if [ -v globstrip ]
			then metaflac --remove-all "$tmp"  # here and not before flac command because will add VORBIS_COMMENT even if empty
			elif [ -v flaclossy ]
			then metaflac --remove --dont-use-padding --except-block-type=VORBIS_COMMENT,PICTURE "$tmp"
				if metaflac --list --block-type=VORBIS_COMMENT "$tmp" | grep -q '^\s\scomments: 0$'
				then metaflac --remove --dont-use-padding --block-type=VORBIS_COMMENT "$tmp"
				else v=$(metaflac --show-vendor-tag "$tmp")
					p=$(($(grep -abom1 "$v" "$tmp" | head -1 | cut -f1 -d:)-7))  # the first match is the vendor-string, use head because -om1 can output more than 1 match
					{ dd status=none bs=$p count=1 iflag=fullblock; p=$((0x$(getBytes '' 0 3)-${#v})); intToBytes $p 3; intToBytes 0 4; dd status=none bs=4k iflag=fullblock iflag=skip_bytes skip=$((4+${#v}));} <"$tmp" >"$tmp2"  # TL;DR: 0xaaabbbb<vendorString>; aaa length metadata block in big endian, bbbb length vendor string in little
					mv "$tmp2" "$tmp"
				fi
			fi
			[ -v a ] && { wait; for p in $a; do metaflac --append "$tmp" <"$tmp".$p.blockNew; rm "$tmp".$p.blockNew; done;};;  # we add PICTUREs back to the FLAC file
		audio/mpeg | audio/mp3 | audio/mpeg3 | audio/x-mpeg-3)
			# TODO detect and compress if mono was encoded as stereo
			# MP3Packer will write "mp3packer2.04-268\n" in the needed *padding* of frames, removing them break the file (as they're needed). We could remove the padding only at the COMPLETELY end of file, even if FFmpeg decode it fine (and same checksum), some softwares will report an error (and if after removing the padding we reuse MP3Packer on it, boom the checksum does not match anymore!!!)
			# TODO change ffmpeg to another software, because convert ID3 tags to TXXX (comment: https://trac.ffmpeg.org/ticket/8996; lyrics: https://trac.ffmpeg.org/ticket/8795; perhaps others); the good thing with ffmpeg is: it can remove ID3 completely, it will convert IDv1 to IDv2, it will use UTF-8 (instead of heavier UTF-16), can remove Xing frame
			#ffCompressStreams "$tmp" mp3  # TODO see if works and doesn't add metadata for example
			# TODO compress album arts (idk if we can embed something else)
			# TODO remove FFmpeg by more binary BASH logic, keep in mind that FFmpeg is only great for the UTF-16 -> UTF-8 conversion (check mp3unicode package) and Xing frame removal
			mp3packer -z --workers 1 "$in" "$tmp" >/dev/null  # mp3packer always adds a Xing/LAME frame
			ffmpeg -v error -y -i "$tmp" -map 0 -c copy -fflags +bitexact -write_xing 0 -metadata_header_padding 10 "$tmp2";  # FFmpeg 6.0 will ALWAYS write at least 10 bytes of padding (even if no ID3 metadata), so I use 10 padding too to prevent unpleasant surprise in the future
			if [ -v globstrip ]
			then mp3packer -s -t  "$tmp2" "$tmp"  >/dev/null  # remove everything that's not the MP3 stream itself
			elif ((v=(0x$(getBytes "$tmp2" 6)<<21|0x$(getBytes "$tmp2" 7)<<14|0x$(getBytes "$tmp2" 8)<<7|0x$(getBytes "$tmp2" 9))-10))  # Easier to do the test after 1st ffmpeg command: if ID3 length is not 10 then trim, otherwise remove completely ID3 (since there is only padding).
			then { dd status=none bs=6 count=1 iflag=fullblock; printf $(printf '\\x%x' $((v>>21)) $((v>>14&127)) $((v>>7&127)) $((v&127))); dd status=none bs=$v count=1 iflag=fullblock iflag=skip_bytes skip=4; dd status=none bs=4k iflag=fullblock iflag=skip_bytes skip=10;} <"$tmp2" >"$tmp"  # will remove the 10 bytes padding; ID3v2 length is big-endian
			else ffmpeg -v error -y -i "$tmp2" -map 0 -c copy -fflags +bitexact -write_xing 0 -id3v2_version 0 "$tmp"
			fi
			# use mp3packer to add Xing frame (with real duration) of 208 bytes (ffmpeg Xing frame is 522), could be even smaller than 208 bytes if I create it myself (since strings "mp3packer" or "Lavf" are written to Xing)
			[ -v mp3lossy ] || mp3packer -u "$tmp" "$tmp2" >/dev/null;;
		image/jpeg)
			#mozjpeg is better at recompressing jpgs then ECT due to some weird overhead ECT adds.  TODO
				#assume a possible 1-2kb gain
			
			mv "$tmp" "$tmp.jpg"
			ect -9 -quiet ${globstrip+-strip} "$tmp.jpg"  # ect needs correct ext
			mv "$tmp.jpg" "$tmp";;
		image/jxl)
			# -e 10 needs libjxl 0.8.0
			# cjxl -e 9 -d 0 --brotli_effort=11 --num_threads=0 -I 100 -g 3 -E 11
			# bruteforcing some settings will compress better (-g 1..3, --patches, ...): https://github.com/libjxl/libjxl/issues/426#issuecomment-898962219
			# -e 10 will actually really bruteforce everything/every flag, no need for more than `-e 10 --allow_expert_options` (if cjxl uses more than 1 thread, no impact on the size) (more args is completely useless)
			
			# strip = '--container=0 --jpeg_store_metadata=0' and perhaps more
			# `-x strip=exif` was added fairly recently, might work with `-x strip=all` but not sure, could try exif and xmp at the same time too
			# code stripping container : https://github.com/Fraetor/jxl_decode/blob/main/src/jxl-strip.py
			
			# jxlinfo prints 'JPEG bitstream reconstruction data available', perhaps with glob-lossy remove that reconstruction (if does not degrade JXL quality - I guess it only change jpg reconstruction)
			;;
		image/png | image/x-png | image/vnd.mozilla.apng)
			# Tested software: ECT, zopflipng_mrkrzych00; zopflipng_mrkrzych00 -y -m --iterations=999 --slowfix --all --lossy_transparent --alpha_cleaners=bhvapw --pass=999 in out
			# ECT is the best Deflate encoder (looking at compression ratio only), so the only way to beat it is to bruteforce even more filters than `ect --allfilters-b --pal_sort=120` (not using this as it takes ages), but then if we find a better filter we could run ect on it and it will reuse the filter if gives better ratio
			# TODO can apngopt sometimes do lossy things (iirc it will change the pixels to rgba(pc)) ?
			# TODO remove useless alpha channel
			if [ $(ffprobe -v warning -show_entries stream=codec_name -of default=nk=1:nw=1 "$tmp") = apng ]
			then # ect -1 ${globstrip+-strip} "$tmp"  # TODO (cannot strip using ECT since it drops all other frames - only 1st one is kept)
				apngopt -z2 -i99${pnginsane+999} "$in" "$tmp" >/dev/null  # TODO to do better, we could split frames, use ECT --reuse, them remux
			else mv "$tmp" "$tmp.png"
				ect -9${pnginsane+9999} --mt-deflate -quiet ${globstrip+-strip} "$tmp.png"  # ect needs correct extension
				mv "$tmp.png" "$tmp"
			fi;;
		image/webp)  # only tested cwebp; cwebp -z9 is NOT always the smallest one! Therefore just bruteforce -z (which is an alias for -m and -q options)
			parallel cwebp -quiet -lossless -alpha_filter best -metadata all -z {} "$tmp" -o "$tmp".{} ::: {0..9}
			catchSmallestFile "$tmp".*;;
		*)
			# application/x-executable (TODO test if this MIME type is the only one for executables)
			#upx -9 --ultra-brute -o out in
			;;
	esac
	(((size-=$(wc -c <"$tmp"))<0)) && { warning "'$in': could not compress further. Input file was kept."; cp "$in" "$tmp"; size=0;}
	rm -f "$tmp2"
	[ -v globkeeptime ] && touch -md"$mtime" "$tmp" && touch -ad"$atime" "$tmp"
	if [ $4 ]
	then sem --id "$globstatsfile" 'set -- $(<"$globstatsfile"); printf "$(('$size'+$1))\n$(('$3'+$2))\n$((1+$3))\n" >"$globstatsfile"'  # use a semaphore to allow only one thread to write at a time
		[[ -v globoutput && ! -v globupdate && -e "$out" ]] && { warning "'$out' already exists, not updated. Compressed version here: '$tmp'.\nRerun with -y to overwrite files in output directory, or with -p to add a prefix.";} || { mv "$tmp" "$out"; chown -f --reference="$in" "$out"; chmod -f --reference="$in" "$out";}
	else mv "$tmp" "$out"
	fi
}

# only one argument, the folder where we extracted the archive contents
compressTmpFolder() {
	[ -v globnorecur ] && find "$1" -type f -printf '%s\0%P\0%H\0' | perl -0ne 'push @rec, $_; if ($#rec == 2) { push @items, join("", @rec); @rec = (); } END { print(join("", sort { $b <=> $a } @items)) }' | parallel -0L3 --lb compressFile {2} {3} {1}
}

warning() { printf "\033[1;33mW: %s\033[0m\n" "$1" >&2;}

error() { printf "\033[1;31mE: %s\033[0m\n" "$1" >&2; exit ${2:-1};}

ctrlCHandler() {
	if [ -v ctrlc ]
	then [ $ctrlc ] || kill $(pstree -ap $$ | grep -m1 parallel | grep -oP '^.*?\K[0-9]+') 2>/dev/null  # we could use `exit 130`, but it's better to only kill `parallel` so we can print information about already processed files (which is done really fast)
		ctrlc=g  # only allow 2 Ctrl+C signals, after that we simply catch and ignore them
	else
		ctrlc=
		{	kill -HUP $(pstree -ap $$ | grep parallel | grep -oP '^.*?\K[0-9]+') 2>/dev/null  # do NOT start any new job in any `parallel` (even grandchild processes)
			sleep .1  # so the following msg will be shown *after* parallel's output about no new job
			printf "\r%${COLUMNS}s\r\033[1;36mHit Ctrl+C again to stop all jobs.\033[0m\n" ''  # erase progress bar from parallel, then print msg
		} &  # run in background so if we hit **again** Ctrl+C super fast (< .1 sec), ctrlCHandler won't be killed
	fi
}

# Set up the Ctrl+C signal handler
trap 'ctrlCHandler' INT  # TODO allow to stop and resume the optimisation (for example with the tool idk the name that can do it only if certain param was set during the kernel compilation; or by simply storing which files were processed but this wouldn't work for big ZIP optimisation)

(($#)) && parseArgs "$@" || parseArgs -h


exit
# add-ins encoded in base64 below this eof line (could append them in binary data, smaller file but many text editors don't support NULL bytes)
#EOF#
